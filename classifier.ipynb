{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corpus(general_glossary, glossary):\n",
    "    v = [0] * len(general_glossary)\n",
    "    for word in glossary['Termino']:\n",
    "        v[general_glossary[word]] = 1\n",
    "    return v\n",
    "\n",
    "def calculate_corpus_new(general_glossary, new):\n",
    "    v = [0] * len(general_glossary)\n",
    "    for word in new:\n",
    "        try:\n",
    "            v[general_glossary[word]] += 1\n",
    "        except:\n",
    "            pass\n",
    "    return v\n",
    "        \n",
    "def cos_distance(v1, v2):\n",
    "    n = sum(map(lambda t: t[0]*t[1], zip(v1, v2)))\n",
    "    dist_v1 = math.sqrt(sum(map(lambda x: x*x, v1)))\n",
    "    dist_v2 = math.sqrt(sum(map(lambda x: x*x, v2)))\n",
    "    d = dist_v1 * dist_v2\n",
    "    return n/d if d != 0 else -1\n",
    "    \n",
    "def read_csv(path, sep):\n",
    "    csv = pd.read_csv(path, sep=sep)\n",
    "    return csv\n",
    "\n",
    "def read_file(path):\n",
    "    return ''.join(str(e) for e in open(path, 'r', encoding='utf-8').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 7, 0, 0, 0, 1, 1, 0, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 2, 0, 1, 0, 6, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
      "Type:  politics\n",
      "[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 2, 0, 1]\n",
      "Type:  politics\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "Type:  sports\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Type:  sports\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Type:  science\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 1, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "Type:  science\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'politics': 2, 'sports': 2, 'science': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the news in ./texts for creating the glossaries that allows to classify the texts properly. We create the glossaries by using SimpleExtractor, by DAIL Software, UPM.\n",
    "\n",
    "# Glossaries reading.\n",
    "politics_glossary = read_csv('./extractions/politics.csv', ';')\n",
    "sports_glossary = read_csv('./extractions/sports.csv', ';')\n",
    "science_glossary = read_csv('./extractions/science.csv', ';')\n",
    "\n",
    "# We create a list which contains the words of the glossaries.\n",
    "common_glossary = set(list(politics_glossary['Termino']) + list(sports_glossary['Termino']) + list(science_glossary['Termino']))\n",
    "only_words =  dict(map(reversed, enumerate(sorted(common_glossary))))\n",
    "\n",
    "# Creation of corpus of each glossary.\n",
    "politics_corpus = calculate_corpus(only_words, politics_glossary)\n",
    "sports_corpus = calculate_corpus(only_words, sports_glossary)\n",
    "science_corpus = calculate_corpus(only_words, science_glossary)\n",
    "\n",
    "# We prepare a set of news to classify. They are in ./predict.\n",
    "news = [read_file('./predict/politics-01.txt'), read_file('./predict/politics-02.txt'),\n",
    "            read_file('./predict/sports-01.txt'), read_file('./predict/sports-02.txt'),\n",
    "            read_file('./predict/science-01.txt'), read_file('./predict/science-02.txt')]\n",
    "\n",
    "# Classification process.\n",
    "news_classification = dict(\n",
    "    map(lambda nombre: (nombre, 0), ('politics', 'sports', 'science'))\n",
    ")\n",
    "\n",
    "pattern = re.compile(r'\\w+')\n",
    "for new in news:\n",
    "    new_words = pattern.findall(new)\n",
    "    new_corpus = calculate_corpus_new(only_words, new_words)\n",
    "    print(new_corpus)\n",
    "\n",
    "    cos_politics = cos_distance(politics_corpus, new_corpus)\n",
    "    cos_sports = cos_distance(sports_corpus, new_corpus)\n",
    "    cos_science = cos_distance(science_corpus, new_corpus)\n",
    "    \n",
    "    if cos_politics > cos_sports:\n",
    "        if cos_politics > cos_science:\n",
    "            new_type = 'politics'\n",
    "        else:\n",
    "            new_type = 'science'\n",
    "    else:\n",
    "        if cos_sports > cos_science:\n",
    "            new_type = 'sports'\n",
    "        else:\n",
    "            new_type = 'science'\n",
    "            \n",
    "    news_classification[new_type] += 1\n",
    "    print('Type: ', new_type)\n",
    "    \n",
    "news_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Además': 0,\n",
       " 'Alonso': 1,\n",
       " 'Andalucía': 2,\n",
       " 'Barcelona': 3,\n",
       " 'Bennu': 4,\n",
       " 'Cataluña': 5,\n",
       " 'Ciencia': 6,\n",
       " 'Clarke': 7,\n",
       " 'Clubes': 8,\n",
       " 'Congreso': 9,\n",
       " 'Consejo': 10,\n",
       " 'Consejo de Ministros': 11,\n",
       " 'Constitución': 12,\n",
       " 'Copa': 13,\n",
       " 'Copa Davis': 14,\n",
       " 'Davis': 15,\n",
       " 'EH Bildu': 16,\n",
       " 'Ejecutivo': 17,\n",
       " 'Enrique': 18,\n",
       " 'Espacial': 19,\n",
       " 'España': 20,\n",
       " 'Estación Espacial': 21,\n",
       " 'Europa': 22,\n",
       " 'Fernando Alonso': 23,\n",
       " 'Foot': 24,\n",
       " 'Fox News': 25,\n",
       " 'General': 26,\n",
       " 'Generalitat': 27,\n",
       " 'Gobierno': 28,\n",
       " 'Gobierno central': 29,\n",
       " 'Gran Premio': 30,\n",
       " 'Historia': 31,\n",
       " 'InSight': 32,\n",
       " 'Liga': 33,\n",
       " 'Little': 34,\n",
       " 'Little Foot': 35,\n",
       " 'Madrid': 36,\n",
       " 'Marte': 37,\n",
       " 'Ministros': 38,\n",
       " 'Mossos': 39,\n",
       " 'MotoGP': 40,\n",
       " 'Mundial': 41,\n",
       " 'Mundial de Clubes': 42,\n",
       " 'Márquez': 43,\n",
       " 'NASA': 44,\n",
       " 'PP y Ciudadanos': 45,\n",
       " 'PSOE': 46,\n",
       " 'Parlamento': 47,\n",
       " 'Pedro': 48,\n",
       " 'Pedro Sánchez': 49,\n",
       " 'Policía Nacional': 50,\n",
       " 'Quim': 51,\n",
       " 'Quim Torra': 52,\n",
       " 'Real': 53,\n",
       " 'Real Madrid': 54,\n",
       " 'Reino Unido': 55,\n",
       " 'Rivera': 56,\n",
       " 'Sistema': 57,\n",
       " 'Sistema Solar': 58,\n",
       " 'Solar': 59,\n",
       " 'Solo': 60,\n",
       " 'Sánchez': 61,\n",
       " 'Tierra': 62,\n",
       " 'Torra': 63,\n",
       " 'Vox': 64,\n",
       " 'Voyager': 65,\n",
       " 'acuerdo': 66,\n",
       " 'adelante': 67,\n",
       " 'además': 68,\n",
       " 'afirma': 69,\n",
       " 'antes': 70,\n",
       " 'artículo': 71,\n",
       " 'asteroide': 72,\n",
       " 'aterrizaje': 73,\n",
       " 'ayuntamiento': 74,\n",
       " 'año': 75,\n",
       " 'años': 76,\n",
       " 'campeón': 77,\n",
       " 'campeón del mundo': 78,\n",
       " 'caso': 79,\n",
       " 'catalán': 80,\n",
       " 'central': 81,\n",
       " 'científicos': 82,\n",
       " 'ciudadanos': 83,\n",
       " 'club': 84,\n",
       " 'derecha': 85,\n",
       " 'diferentes': 86,\n",
       " 'donde': 87,\n",
       " 'día': 88,\n",
       " 'días': 89,\n",
       " 'elecciones': 90,\n",
       " 'elecciones andaluzas': 91,\n",
       " 'embargo': 92,\n",
       " 'equipo': 93,\n",
       " 'eslovena': 94,\n",
       " 'espacio': 95,\n",
       " 'estudio': 96,\n",
       " 'euros': 97,\n",
       " 'extrema derecha': 98,\n",
       " 'fin de semana': 99,\n",
       " 'final': 100,\n",
       " 'forma': 101,\n",
       " 'gran': 102,\n",
       " 'guerra': 103,\n",
       " 'hace': 104,\n",
       " 'hecho': 105,\n",
       " 'historia': 106,\n",
       " 'idea': 107,\n",
       " 'importante': 108,\n",
       " 'incluso': 109,\n",
       " 'independencia': 110,\n",
       " 'investigadores': 111,\n",
       " 'jugador': 112,\n",
       " 'jugadores': 113,\n",
       " 'kilómetros': 114,\n",
       " 'ley': 115,\n",
       " 'llegó': 116,\n",
       " 'masa': 117,\n",
       " 'materia': 118,\n",
       " 'mayor': 119,\n",
       " 'mayoría': 120,\n",
       " 'mejores': 121,\n",
       " 'mientras': 122,\n",
       " 'minutos': 123,\n",
       " 'misión': 124,\n",
       " 'mismo': 125,\n",
       " 'momento': 126,\n",
       " 'muchos': 127,\n",
       " 'mujeres': 128,\n",
       " 'mundo': 129,\n",
       " 'nacional': 130,\n",
       " 'nave': 131,\n",
       " 'nueva': 132,\n",
       " 'nueva Copa': 133,\n",
       " 'nueva Copa Davis': 134,\n",
       " 'nuevo': 135,\n",
       " 'nuevo formato': 136,\n",
       " 'número': 137,\n",
       " 'octubre': 138,\n",
       " 'operación': 139,\n",
       " 'otros': 140,\n",
       " 'parte': 141,\n",
       " 'partido': 142,\n",
       " 'partidos': 143,\n",
       " 'pasado': 144,\n",
       " 'país': 145,\n",
       " 'piloto': 146,\n",
       " 'planeta': 147,\n",
       " 'policía': 148,\n",
       " 'política': 149,\n",
       " 'políticos': 150,\n",
       " 'portavoz': 151,\n",
       " 'presidente': 152,\n",
       " 'primer': 153,\n",
       " 'primera': 154,\n",
       " 'problema': 155,\n",
       " 'propuesta': 156,\n",
       " 'puntos': 157,\n",
       " 'región': 158,\n",
       " 'seguridad': 159,\n",
       " 'semana': 160,\n",
       " 'situación': 161,\n",
       " 'solo': 162,\n",
       " 'sonda': 163,\n",
       " 'superficie': 164,\n",
       " 'sólo': 165,\n",
       " 'tanto': 166,\n",
       " 'temporada': 167,\n",
       " 'tiempo': 168,\n",
       " 'toda': 169,\n",
       " 'todas': 170,\n",
       " 'todo': 171,\n",
       " 'todos': 172,\n",
       " 'vez': 173,\n",
       " 'victoria': 174,\n",
       " 'vida': 175,\n",
       " 'viento': 176,\n",
       " 'viento solar': 177,\n",
       " 'vía': 178,\n",
       " 'vía eslovena': 179,\n",
       " 'último': 180}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science_corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
