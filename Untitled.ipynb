{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "def abrir_csv_simple_extractor(nombre_del_fichero):\n",
    "    with open(nombre_del_fichero, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        reader_it = iter(reader)\n",
    "        next(reader_it) # quitamos la primera fila\n",
    "        for row in reader_it: yield (row[0], int(row[1]), int(row[2]))\n",
    "\n",
    "def quitar_comunes(comunes, datos):\n",
    "    return filter(lambda t: t[0] not in comunes, datos)\n",
    "\n",
    "def ordenar_por_apariciones_y_tamano_inverso(datos):\n",
    "    return sorted(datos, key = lambda t: (t[1], -t[2]))\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    return ''.join( map(lambda w: w if w.isupper() else w.lower(), re.split(r\"(\\W+)\", texto)) )\n",
    "\n",
    "def limpiar_textos(textos):\n",
    "    patron_de_espacios = r'[^\\s]+'\n",
    "    textos_con_una_sola_linea = map( lambda txt: ' '.join( patron_de_espacios.findall(txt) ), textos )\n",
    "\n",
    "    return list(map(limpiar_texto, textos_con_una_sola_linea))\n",
    "\n",
    "def apariciones_por_texto(palabras, textos):\n",
    "    palabras_por_tamano = sorted(palabras, key = lambda x: -len(x))\n",
    "    regla = '[^\\w](%s)[^\\w]' % '|'.join(map(lambda w: re.escape(w), palabras_por_tamano))\n",
    "    patron = re.compile(regla)\n",
    "\n",
    "    for texto in textos:\n",
    "        yield [ x for x in patron.findall(' %s ' % texto) ]\n",
    "\n",
    "def idf(palabras, textos):\n",
    "    n = 0\n",
    "    c = dict( (p, 0) for p in palabras )\n",
    "\n",
    "    for ocurrencias in apariciones_por_texto(palabras, textos):\n",
    "        for x in set(ocurrencias):\n",
    "            c[x] += 1\n",
    "        n += 1\n",
    "\n",
    "    return [(math.log(n/cont), p) for p, cont in c.items() if cont != 0]\n",
    "\n",
    "def noticias_del_json(nombre_fichero_json):\n",
    "    with open(nombre_fichero_json, 'r') as f:\n",
    "        resultados = json.load(f)\n",
    "        return resultados['noticias']\n",
    "\n",
    "def ordenar_por_idf(nombre_fichero_json, palabras_a_contar, palabras_prohibidas = []):\n",
    "    noticias = noticias_del_json(nombre_fichero_json)\n",
    "\n",
    "    lista_de_palabras = list(\n",
    "            map(\n",
    "                lambda x: limpiar_texto(x[0]), \n",
    "                palabras_a_contar\n",
    "            )\n",
    "    )\n",
    "\n",
    "    textos_de_noticias_filtrados = filter(\n",
    "            lambda txt: not any( map(lambda pat: txt.find(pat) != -1, palabras_prohibidas) ),\n",
    "            map(lambda x: x['texto'], noticias)\n",
    "    )\n",
    "\n",
    "    resultados_idf = idf(lista_de_palabras, textos_de_noticias_filtrados)\n",
    "\n",
    "    return sorted(resultados_idf)\n",
    "\n",
    "def lista_del_corpus(fichero_glosario):\n",
    "    with open(fichero_glosario) as f:\n",
    "        return list( map(lambda x: x.strip(), f.readlines()) )\n",
    "\n",
    "def crear_vector_del_corpus(posicion_de_cada_palabra, corpus):\n",
    "    vector = [0] * len(posicion_de_cada_palabra)\n",
    "    for palabra in corpus:\n",
    "        vector[posicion_de_cada_palabra[palabra]] = 1\n",
    "    return vector\n",
    "\n",
    "def crear_vector_por_texto(posicion_de_cada_palabra, textos):\n",
    "    for ocurrencias in apariciones_por_texto(posicion_de_cada_palabra.keys(), textos):\n",
    "        vector = [0] * len(posicion_de_cada_palabra)\n",
    "        for palabra in ocurrencias:\n",
    "            vector[posicion_de_cada_palabra[palabra]] += 1\n",
    "        yield vector\n",
    "\n",
    "def distancia_del_coseno(v1, v2):\n",
    "    numerador = sum(map(lambda t: t[0]*t[1], zip(v1, v2)))\n",
    "    distancia_v1 = math.sqrt(sum(map(lambda x: x*x, v1)))\n",
    "    distancia_v2 = math.sqrt(sum(map(lambda x: x*x, v2)))\n",
    "    denomiandor = distancia_v1 * distancia_v2\n",
    "\n",
    "    return numerador / denomiandor if denomiandor != 0 else -1\n",
    "\n",
    "def main_corpus(args):\n",
    "    fichero_animales = args[1]\n",
    "    fichero_economia = args[2]\n",
    "    fichero_futbol = args[3]\n",
    "    json_animales = args[4]\n",
    "    json_economia = args[5]\n",
    "    json_futbol = args[6]\n",
    "\n",
    "    ficheros_csv = (fichero_animales, fichero_economia, fichero_futbol)\n",
    "\n",
    "    datos_por_fichero = [ list(abrir_csv_simple_extractor(fichero_csv)) for fichero_csv in ficheros_csv ]\n",
    "\n",
    "    datos_animales, datos_economia, datos_futbol = datos_por_fichero\n",
    "    set_animales, set_economia, set_futbol = [ set(map(lambda x: limpiar_texto(x[0]), datos)) for datos in datos_por_fichero ]\n",
    "\n",
    "    comunes_a_los_tres = set_animales.intersection( set_economia ).intersection( set_futbol )\n",
    "\n",
    "    no_comunes_animales = list( quitar_comunes(comunes_a_los_tres, datos_por_fichero[0]) )\n",
    "    no_comunes_economia = list( quitar_comunes(comunes_a_los_tres, datos_por_fichero[1]) )\n",
    "    no_comunes_futbol   = list( quitar_comunes(comunes_a_los_tres, datos_por_fichero[2]) )\n",
    "\n",
    "    minimo_de_repeticiones = 10\n",
    "    filtrar_por_tamano = lambda x: filter(\n",
    "        lambda x: x[1] > minimo_de_repeticiones, \n",
    "        x\n",
    "    )\n",
    "\n",
    "    # for idf, palabra in ordenar_por_idf(\n",
    "            # json_animales,\n",
    "            # filtrar_por_tamano( no_comunes_animales )\n",
    "    # ):\n",
    "        # print(palabra)\n",
    "\n",
    "    for idf, palabra in ordenar_por_idf(\n",
    "            json_economia,\n",
    "            filtrar_por_tamano( no_comunes_economia )\n",
    "    ):\n",
    "        print(palabra)\n",
    "\n",
    "    # for idf, palabra in ordenar_por_idf(\n",
    "            # json_futbol,\n",
    "            # filtrar_por_tamano( no_comunes_futbol ),\n",
    "            # palabras_prohibidas = ['accidente aéreo', 'superviviente', 'siniestro', 'estrelló', 'equip', 'tragedia aérea' ]\n",
    "    # ):\n",
    "        # print(palabra)\n",
    "\n",
    "def main_corpus_con_peso(args):\n",
    "    fichero_glosario = args[1]\n",
    "    fichero_json = args[2]\n",
    "\n",
    "    glosario = lista_del_corpus(fichero_glosario)\n",
    "    noticias = noticias_del_json(fichero_json)\n",
    "    textos = map(lambda x: x['texto'], noticias)\n",
    "\n",
    "    apariciones_por_palabra = dict(map(lambda x: (x, [1]), glosario))\n",
    "\n",
    "    for palabras_encontradas in apariciones_por_texto(glosario, textos):\n",
    "        d = {}\n",
    "        for w in palabras_encontradas:\n",
    "            if w in d:\n",
    "                d[w] += 1\n",
    "            else:\n",
    "                d[w] = 1\n",
    "\n",
    "        for w, c in d.items():\n",
    "            apariciones_por_palabra[w].append(c)\n",
    "\n",
    "    for w, apariciones in apariciones_por_palabra.items():\n",
    "        apariciones.sort()\n",
    "        moda_de_apariciones = apariciones[len(apariciones)//2]\n",
    "        print('%d,%s' % (moda_de_apariciones, w))\n",
    "\n",
    "def main_similitud(args):\n",
    "    fichero_glosario_animales = args[1]\n",
    "    fichero_glosario_economia = args[2]\n",
    "    fichero_glosario_futbol = args[3]\n",
    "    nombre_fichero_json = args[4]\n",
    "\n",
    "    glosario_animales = lista_del_corpus(fichero_glosario_animales)\n",
    "    glosario_economia = lista_del_corpus(fichero_glosario_economia)\n",
    "    glosario_futbol = lista_del_corpus(fichero_glosario_futbol)\n",
    "\n",
    "    glosario_comun = set(chain(glosario_animales, glosario_economia, glosario_futbol))\n",
    "\n",
    "    # Lo que se hace en la siguiente linea es lo siguiente:\n",
    "    #  - Ordenamos las palabras por orden alfabetico\n",
    "    #  - Le añadimos la posición\n",
    "    #  - Revertimos la tupla para que primero este la palabra y luego la posición\n",
    "    #  - Creamos un diccionario de palabras con su posición correspondiente\n",
    "    posicion_de_cada_palabra = dict(map(reversed, enumerate(sorted(glosario_comun))))\n",
    "\n",
    "    vector_corpus_animales = crear_vector_del_corpus(posicion_de_cada_palabra, glosario_animales)\n",
    "    vector_corpus_economia = crear_vector_del_corpus(posicion_de_cada_palabra, glosario_economia)\n",
    "    vector_corpus_futbol = crear_vector_del_corpus(posicion_de_cada_palabra, glosario_futbol)\n",
    "\n",
    "    noticias = noticias_del_json(nombre_fichero_json)\n",
    "    contador_de_noticias = dict(\n",
    "            map(\n",
    "                lambda nombre: (nombre, 0),\n",
    "                (\"animales\", \"fútbol\", \"economia\")\n",
    "            )\n",
    "    )\n",
    "\n",
    "    for vector_por_noticia, encabezado in zip(\n",
    "            crear_vector_por_texto(\n",
    "                    posicion_de_cada_palabra, \n",
    "                    map(lambda x: x['texto'], noticias)\n",
    "            ),\n",
    "            map(lambda x: x['encabezado'], noticias)\n",
    "    ):\n",
    "        coseno_animales = distancia_del_coseno(vector_corpus_animales, vector_por_noticia)\n",
    "        coseno_economia = distancia_del_coseno(vector_corpus_economia, vector_por_noticia)\n",
    "        coseno_futbol   = distancia_del_coseno(vector_corpus_futbol  , vector_por_noticia)\n",
    "\n",
    "        if coseno_animales > coseno_economia:\n",
    "            if coseno_animales > coseno_futbol:\n",
    "                tipo_de_noticia = \"animales\"\n",
    "            else:\n",
    "                tipo_de_noticia = \"fútbol\"\n",
    "        else:\n",
    "            if coseno_economia > coseno_futbol:\n",
    "                tipo_de_noticia = \"economia\"\n",
    "            else:\n",
    "                tipo_de_noticia = \"fútbol\"\n",
    "\n",
    "        contador_de_noticias[tipo_de_noticia] += 1\n",
    "        print('Título: \"%s\"' % encabezado.strip())\n",
    "        print(\"Tipo: %s\" % tipo_de_noticia)\n",
    "        print(\" ----------------------------- \")\n",
    "\n",
    "    for noticia, contador in contador_de_noticias.items():\n",
    "        print(\"%s: %d\" % (noticia, contador))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #main_corpus(sys.argv)\n",
    "    #main_corpus_con_peso(sys.argv)\n",
    "    main_similitud(sys.argv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
